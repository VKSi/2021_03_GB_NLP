{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW5-task2-colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VKSi/2021_03_GB_NLP/blob/main/HW5_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cINqgGpKXURp"
      },
      "source": [
        "# Задание 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCM0drjKXYet"
      },
      "source": [
        "много дополнительных датасетов на русском языке\n",
        "\n",
        "https://natasha.github.io/corus/  \n",
        "https://github.com/natasha/corus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUOg4C8sZNpw"
      },
      "source": [
        "мы будем использовать данные http://ai-center.botik.ru/Airec/index.php/ru/collections/28-persons-1000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzi6ApNLZg6X"
      },
      "source": [
        "**Проверить насколько хорошо работает NER**\n",
        "\n",
        "1. взять нер из nltk\n",
        "2. проверить deeppavlov\n",
        "3. написать свой нер попробовать разные подходы (с доп информацией без) так же с учётом соседей и без них\n",
        "4. сделать выводы по вашим экспериментам какой из подходов успешнее справляется"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aP1LgaNUtaOz"
      },
      "source": [
        "при обучении своего нера незабудьте разделить выборку"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qg6tcss2Zhp9",
        "outputId": "10948a2d-7918-475f-aaab-ca96922a9b01"
      },
      "source": [
        "!pip install corus"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: corus in /usr/local/lib/python3.7/dist-packages (0.9.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrc5ocDkaS1e"
      },
      "source": [
        "import corus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPG7VIZJbH76",
        "outputId": "8531ad93-77a4-46d6-f897-5f56e91ec27c"
      },
      "source": [
        "!wget http://ai-center.botik.ru/Airec/ai-resources/Persons-1000.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-18 18:29:30--  http://ai-center.botik.ru/Airec/ai-resources/Persons-1000.zip\n",
            "Resolving ai-center.botik.ru (ai-center.botik.ru)... 95.129.138.2\n",
            "Connecting to ai-center.botik.ru (ai-center.botik.ru)|95.129.138.2|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3363777 (3.2M) [application/zip]\n",
            "Saving to: ‘Persons-1000.zip.1’\n",
            "\n",
            "Persons-1000.zip.1  100%[===================>]   3.21M  1.17MB/s    in 2.8s    \n",
            "\n",
            "2021-04-18 18:29:33 (1.17 MB/s) - ‘Persons-1000.zip.1’ saved [3363777/3363777]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmGWX23KbUfI",
        "outputId": "714416e7-e4a5-46fa-c80b-12ca47812605"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Persons-1000.zip  Persons-1000.zip.1  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmJr9tubbTVk"
      },
      "source": [
        "path = 'Persons-1000.zip'\n",
        "records = corus.persons.load_persons(path)\n",
        "rec = next(records)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzQutiCephkx",
        "outputId": "4b929a7a-5903-472b-ca4f-6f9252bb01b0"
      },
      "source": [
        "rec"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PersonsMarkup(\n",
              "    text='Россия рассчитывает на конструктивное воздействие США на Грузию\\r\\n\\r\\n04/08/2008 12:08\\r\\n\\r\\nМОСКВА, 4 авг - РИА Новости. Россия рассчитывает, что США воздействуют на Тбилиси в связи с обострением ситуации в зоне грузино-осетинского конфликта. Об этом статс-секретарь - заместитель министра иностранных дел России Григорий Карасин заявил в телефонном разговоре с заместителем госсекретаря США Дэниэлом Фридом.\\r\\n\\r\\n\"С российской стороны выражена глубокая озабоченность в связи с новым витком напряженности вокруг Южной Осетии, противозаконными действиями грузинской стороны по наращиванию своих вооруженных сил в регионе, бесконтрольным строительством фортификационных сооружений\", - говорится в сообщении.\\r\\n\\r\\n\"Россия уже призвала Тбилиси к ответственной линии и рассчитывает также на конструктивное воздействие со стороны Вашингтона\", - сообщил МИД России. ',\n",
              "    spans=[PersonsSpan(\n",
              "         id=1,\n",
              "         start=308,\n",
              "         stop=324,\n",
              "         value='ГРИГОРИЙ КАРАСИН'\n",
              "     ), PersonsSpan(\n",
              "         id=2,\n",
              "         start=387,\n",
              "         stop=402,\n",
              "         value='ДЭНИЭЛ ФРИД'\n",
              "     )]\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utanZXahn-2I",
        "outputId": "d1506e17-3a19-4a70-9679-16b59d1bd1ba"
      },
      "source": [
        "print(rec.text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Россия рассчитывает на конструктивное воздействие США на Грузию\r\n",
            "\r\n",
            "04/08/2008 12:08\r\n",
            "\r\n",
            "МОСКВА, 4 авг - РИА Новости. Россия рассчитывает, что США воздействуют на Тбилиси в связи с обострением ситуации в зоне грузино-осетинского конфликта. Об этом статс-секретарь - заместитель министра иностранных дел России Григорий Карасин заявил в телефонном разговоре с заместителем госсекретаря США Дэниэлом Фридом.\r\n",
            "\r\n",
            "\"С российской стороны выражена глубокая озабоченность в связи с новым витком напряженности вокруг Южной Осетии, противозаконными действиями грузинской стороны по наращиванию своих вооруженных сил в регионе, бесконтрольным строительством фортификационных сооружений\", - говорится в сообщении.\r\n",
            "\r\n",
            "\"Россия уже призвала Тбилиси к ответственной линии и рассчитывает также на конструктивное воздействие со стороны Вашингтона\", - сообщил МИД России. \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBaxNLbQoucW",
        "outputId": "31270b2a-7add-4450-8d91-3fbc7d3aef94"
      },
      "source": [
        "rec.spans"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PersonsSpan(\n",
              "     id=1,\n",
              "     start=308,\n",
              "     stop=324,\n",
              "     value='ГРИГОРИЙ КАРАСИН'\n",
              " ), PersonsSpan(\n",
              "     id=2,\n",
              "     start=387,\n",
              "     stop=402,\n",
              "     value='ДЭНИЭЛ ФРИД'\n",
              " )]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ku7z5W_mnpFF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oRyOTnGtVSw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91290069-e896-4813-c1a1-43daa4dda493"
      },
      "source": [
        "!pip install razdel"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: razdel in /usr/local/lib/python3.7/dist-packages (0.5.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hv4GhkdztVNC"
      },
      "source": [
        "from razdel import tokenize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogf5-MIR9Dnu"
      },
      "source": [
        "records = corus.persons.load_persons(path)\n",
        "words_docs = []\n",
        "for ix, rec in enumerate(records):\n",
        "    words = []\n",
        "    for token in tokenize(rec.text):\n",
        "        is_person = False\n",
        "        for person in rec.spans:\n",
        "            if (token.start >= person.start) and (token.stop <= person.stop):\n",
        "                is_person = True\n",
        "                break\n",
        "        words.append([token.text, 'PERSON' if is_person else 'NO_PERSON'])\n",
        "    words_docs.extend(words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QDyvu17_i0z"
      },
      "source": [
        "Подстрою предложенный подход непосредственно под наше залание. Нам достаточно отслеживать множество персон:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAm1t8Bq34sD"
      },
      "source": [
        "records = corus.persons.load_persons(path)\n",
        "person_set = set([])\n",
        "for ix, rec in enumerate(records):\n",
        "  for token in tokenize(rec.text):\n",
        "    is_person = False\n",
        "    for person in rec.spans:\n",
        "        if (token.start >= person.start) and (token.stop <= person.stop):\n",
        "            is_person = True\n",
        "            break\n",
        "    if is_person:\n",
        "      person_set.add(token.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELOiCSmY-rfj"
      },
      "source": [
        "теперь у нас есть слово и тег персона или нет, уже можно что-то делать(пробовать какие-то мл алгоритмы)  \n",
        "*дополнительно попробуйте проанализировать все ли токены если рассматривать униграмный подход относятся к тегам персона с логической точки зрения"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMg8h9tO-kV0",
        "outputId": "f3b89592-0ab4-4dbe-ed8f-c19434e543c3"
      },
      "source": [
        "len(person_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5294"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xtam1-3-kMY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e69c8dd-6f41-462d-e44d-6e8f38679399"
      },
      "source": [
        "person_set.intersection(set(['Хаммарберг']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Хаммарберг'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IY448_DCxvv0"
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMT1GedE2PX8",
        "outputId": "98e9f3cc-73b3-429d-80b6-2f96a69b780d"
      },
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger_ru')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_ru is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XymGraMI7xxD"
      },
      "source": [
        "records = corus.persons.load_persons(path)\n",
        "nltk_person_set = set([])\n",
        "for rec in records:\n",
        "  nltk_person_set = nltk_person_set.union({' '.join(c[0] for c in chunk) for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(rec.text))) if (hasattr(chunk, 'label') and chunk.label() == 'PERSON') })"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NORMeatS5oej",
        "outputId": "a46287da-d43b-43da-daf5-dff9660d3878"
      },
      "source": [
        "len(nltk_person_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4882"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skYaNCiC5xM4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be18a26d-af90-403d-df88-ef49f7b94953"
      },
      "source": [
        "nltk_person_set.intersection(set(['Хаммарберг']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Хаммарберг'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gc4gQSlI7gCw",
        "outputId": "c07c1724-5396-4b24-80bd-aba1a443e4a6"
      },
      "source": [
        "print(f'recall = {len(nltk_person_set.intersection(person_set))/len(person_set)*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "recall = 18.28%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPrMHq5b7f-S",
        "outputId": "3291abdd-c848-4b98-de4b-42f2f2c907df"
      },
      "source": [
        "len(nltk_person_set - person_set)/len(person_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7393275406120136"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtMpApMV7f1i",
        "outputId": "3f5e07ae-95ef-40eb-c289-08f504b51597"
      },
      "source": [
        "len(person_set - nltk_person_set)/len(person_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8171514922553834"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzKYTFXr8zlt"
      },
      "source": [
        " Совпало только 18% сущностей, определенных нами ранее как \"персоны\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kd-emBao1u-",
        "outputId": "6ce6da8d-9acf-4c21-c42b-3f4eafaf1f43"
      },
      "source": [
        "   # установка deeppavlov\n",
        "\n",
        "!pip uninstall -y tensorflow tensorflow-gpu\n",
        "!pip install numpy scipy librosa unidecode inflect librosa transformers\n",
        "!pip install deeppavlov"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-1.15.2:\n",
            "  Successfully uninstalled tensorflow-1.15.2\n",
            "\u001b[33mWARNING: Skipping tensorflow-gpu as it is not installed.\u001b[0m\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.18.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (1.4.1)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.0)\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.7/dist-packages (1.2.0)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.7/dist-packages (2.1.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.5.1)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (2.1.9)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.10.3.post1)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.51.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.3.0)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.21.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.22.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.35)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.9.0->librosa) (1.14.5)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (54.2.0)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.9.0->librosa) (2.20)\n",
            "Requirement already satisfied: deeppavlov in /usr/local/lib/python3.7/dist-packages (0.14.1)\n",
            "Requirement already satisfied: sacremoses==0.0.35 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (0.0.35)\n",
            "Requirement already satisfied: pandas==0.25.3 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (0.25.3)\n",
            "Requirement already satisfied: prometheus-client==0.7.1 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (0.7.1)\n",
            "Requirement already satisfied: scikit-learn==0.21.2 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (0.21.2)\n",
            "Requirement already satisfied: Cython==0.29.14 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (0.29.14)\n",
            "Requirement already satisfied: requests==2.22.0 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (2.22.0)\n",
            "Requirement already satisfied: fastapi==0.47.1 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (0.47.1)\n",
            "Requirement already satisfied: pydantic==1.3 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (1.3)\n",
            "Requirement already satisfied: filelock==3.0.12 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (3.0.12)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (1.4.1)\n",
            "Requirement already satisfied: click==7.1.2 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (7.1.2)\n",
            "Requirement already satisfied: numpy==1.18.0 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (1.18.0)\n",
            "Requirement already satisfied: uvicorn==0.11.7 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (0.11.7)\n",
            "Requirement already satisfied: pymorphy2==0.8 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (0.8)\n",
            "Requirement already satisfied: uvloop==0.14.0 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (0.14.0)\n",
            "Requirement already satisfied: aio-pika==6.4.1 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (6.4.1)\n",
            "Requirement already satisfied: overrides==2.7.0 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (2.7.0)\n",
            "Requirement already satisfied: nltk==3.4.5 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (3.4.5)\n",
            "Requirement already satisfied: pytz==2019.1 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (2019.1)\n",
            "Requirement already satisfied: h5py==2.10.0 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (2.10.0)\n",
            "Requirement already satisfied: pyopenssl==19.1.0 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (19.1.0)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (2.4.417127.4579844)\n",
            "Requirement already satisfied: rusenttokenize==0.0.5 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (0.0.5)\n",
            "Requirement already satisfied: pytelegrambotapi==3.6.7 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (3.6.7)\n",
            "Requirement already satisfied: ruamel.yaml==0.15.100 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (0.15.100)\n",
            "Requirement already satisfied: tqdm==4.41.1 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (4.41.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses==0.0.35->deeppavlov) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses==0.0.35->deeppavlov) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from pandas==0.25.3->deeppavlov) (2.8.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->deeppavlov) (2020.12.5)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->deeppavlov) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->deeppavlov) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->deeppavlov) (2.8)\n",
            "Requirement already satisfied: starlette<=0.12.9,>=0.12.9 in /usr/local/lib/python3.7/dist-packages (from fastapi==0.47.1->deeppavlov) (0.12.9)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.7/dist-packages (from uvicorn==0.11.7->deeppavlov) (0.9.0)\n",
            "Requirement already satisfied: httptools==0.1.*; sys_platform != \"win32\" and sys_platform != \"cygwin\" and platform_python_implementation != \"PyPy\" in /usr/local/lib/python3.7/dist-packages (from uvicorn==0.11.7->deeppavlov) (0.1.1)\n",
            "Requirement already satisfied: websockets==8.* in /usr/local/lib/python3.7/dist-packages (from uvicorn==0.11.7->deeppavlov) (8.1)\n",
            "Requirement already satisfied: dawg-python>=0.7 in /usr/local/lib/python3.7/dist-packages (from pymorphy2==0.8->deeppavlov) (0.7.2)\n",
            "Requirement already satisfied: pymorphy2-dicts<3.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from pymorphy2==0.8->deeppavlov) (2.4.393442.3710985)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2==0.8->deeppavlov) (0.6.2)\n",
            "Requirement already satisfied: yarl in /usr/local/lib/python3.7/dist-packages (from aio-pika==6.4.1->deeppavlov) (1.6.3)\n",
            "Requirement already satisfied: aiormq<4,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from aio-pika==6.4.1->deeppavlov) (3.3.1)\n",
            "Requirement already satisfied: cryptography>=2.8 in /usr/local/lib/python3.7/dist-packages (from pyopenssl==19.1.0->deeppavlov) (3.4.7)\n",
            "Requirement already satisfied: multidict>=4.0 in /usr/local/lib/python3.7/dist-packages (from yarl->aio-pika==6.4.1->deeppavlov) (5.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from yarl->aio-pika==6.4.1->deeppavlov) (3.7.4.3)\n",
            "Requirement already satisfied: pamqp==2.3.0 in /usr/local/lib/python3.7/dist-packages (from aiormq<4,>=3.2.0->aio-pika==6.4.1->deeppavlov) (2.3.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.8->pyopenssl==19.1.0->deeppavlov) (1.14.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.8->pyopenssl==19.1.0->deeppavlov) (2.20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KY96lqBzsZJ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "985ad4f8-1dcd-4987-f619-db40717003c8"
      },
      "source": [
        "!python -m deeppavlov install squad_bert\n",
        "!python -m deeppavlov install ner_ontonotes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-18 18:31:32.192 INFO in 'deeppavlov.core.common.file'['file'] at line 32: Interpreting 'squad_bert' as '/usr/local/lib/python3.7/dist-packages/deeppavlov/configs/squad/squad_bert.json'\n",
            "Collecting tensorflow==1.15.2\n",
            "  Using cached https://files.pythonhosted.org/packages/5b/81/84fb7a323f9723f81edfc796d89e89aa95a9446ed7353c144195b3a3a3ba/tensorflow-1.15.2-cp37-cp37m-manylinux2010_x86_64.whl\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.2.0)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.12.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.15.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.18.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.32.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.12.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (3.12.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.36.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.8.1)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.2.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.1.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.3.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (54.2.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (1.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.2) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.10.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.4.1)\n",
            "Installing collected packages: tensorflow\n",
            "Successfully installed tensorflow-1.15.2\n",
            "Collecting git+https://github.com/deepmipt/bert.git@feat/multi_gpu\n",
            "  Cloning https://github.com/deepmipt/bert.git (to revision feat/multi_gpu) to /tmp/pip-req-build-2e6emph_\n",
            "  Running command git clone -q https://github.com/deepmipt/bert.git /tmp/pip-req-build-2e6emph_\n",
            "Requirement already satisfied (use --upgrade to upgrade): bert-dp==1.0 from git+https://github.com/deepmipt/bert.git@feat/multi_gpu in /usr/local/lib/python3.7/dist-packages\n",
            "Building wheels for collected packages: bert-dp\n",
            "  Building wheel for bert-dp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-dp: filename=bert_dp-1.0-cp37-none-any.whl size=23581 sha256=ac996cff4d8b25d8f9ff3941ef5c0616b6bd690d3813569ee2478675573d9ae0\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-21dg43_d/wheels/1e/41/94/886107eaf932532594886fd8bfc9cb9d4db632e94add49d326\n",
            "Successfully built bert-dp\n",
            "2021-04-18 18:31:59.61 INFO in 'deeppavlov.core.common.file'['file'] at line 32: Interpreting 'ner_ontonotes' as '/usr/local/lib/python3.7/dist-packages/deeppavlov/configs/ner/ner_ontonotes.json'\n",
            "Requirement already satisfied: tensorflow==1.15.2 in /usr/local/lib/python3.7/dist-packages (1.15.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (3.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.15.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.18.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.1.2)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.2.2)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.36.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.32.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (3.12.4)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.12.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.8.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.0.8)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.15.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (54.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (1.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.2) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.10.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.4.1)\n",
            "Requirement already satisfied: gensim==3.8.1 in /usr/local/lib/python3.7/dist-packages (3.8.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.1) (5.0.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.1) (1.18.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.1) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.1) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KE7tpVWs1b7"
      },
      "source": [
        "import deeppavlov\n",
        "from deeppavlov import configs, build_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4OY9GqsCZih",
        "outputId": "c6ebd7b7-f3fc-4e2b-e739-f11d619673bf"
      },
      "source": [
        "ner_model = build_model(configs.ner.ner_ontonotes_bert_mult, download=True)\n",
        "rus_document = \"Нью-Йорк, США, 30 апреля 2020, 01:01 — REGNUM В администрации президента США Дональда Трампа планируют пройти все этапы создания вакцины от коронавируса в ускоренном темпе и выпустить 100 млн доз до конца 2020 года, передаёт агентство Bloomberg со ссылкой на осведомлённые источники\"\n",
        "ner_model([rus_document])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-18 18:32:21.757 INFO in 'deeppavlov.download'['download'] at line 138: Skipped http://files.deeppavlov.ai/deeppavlov_data/bert/multi_cased_L-12_H-768_A-12.zip download because of matching hashes\n",
            "2021-04-18 18:32:39.90 INFO in 'deeppavlov.download'['download'] at line 138: Skipped http://files.deeppavlov.ai/deeppavlov_data/ner_ontonotes_bert_mult_v1.tar.gz download because of matching hashes\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package perluniprops to /root/nltk_data...\n",
            "[nltk_data]   Package perluniprops is already up-to-date!\n",
            "[nltk_data] Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package nonbreaking_prefixes is already up-to-date!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-18 18:32:41.430 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes_bert_mult/tag.dict]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:37: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:193: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:236: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:314: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:178: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:418: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:499: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:366: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:680: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:283: The name tf.erf is deprecated. Please use tf.math.erf instead.\n",
            "\n",
            "WARNING:tensorflow:Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:75: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/crf/python/ops/crf.py:213: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:234: The name tf.train.AdadeltaOptimizer is deprecated. Please use tf.compat.v1.train.AdadeltaOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:131: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:131: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:94: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:671: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:244: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:249: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-18 18:33:16.323 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /root/.deeppavlov/models/ner_ontonotes_bert_mult/model]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:54: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/ner_ontonotes_bert_mult/model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[['Нью',\n",
              "   '-',\n",
              "   'Йорк',\n",
              "   ',',\n",
              "   'США',\n",
              "   ',',\n",
              "   '30',\n",
              "   'апреля',\n",
              "   '2020',\n",
              "   ',',\n",
              "   '01',\n",
              "   ':',\n",
              "   '01',\n",
              "   '—',\n",
              "   'REGNUM',\n",
              "   'В',\n",
              "   'администрации',\n",
              "   'президента',\n",
              "   'США',\n",
              "   'Дональда',\n",
              "   'Трампа',\n",
              "   'планируют',\n",
              "   'пройти',\n",
              "   'все',\n",
              "   'этапы',\n",
              "   'создания',\n",
              "   'вакцины',\n",
              "   'от',\n",
              "   'коронавируса',\n",
              "   'в',\n",
              "   'ускоренном',\n",
              "   'темпе',\n",
              "   'и',\n",
              "   'выпустить',\n",
              "   '100',\n",
              "   'млн',\n",
              "   'доз',\n",
              "   'до',\n",
              "   'конца',\n",
              "   '2020',\n",
              "   'года',\n",
              "   ',',\n",
              "   'передаёт',\n",
              "   'агентство',\n",
              "   'Bloomberg',\n",
              "   'со',\n",
              "   'ссылкой',\n",
              "   'на',\n",
              "   'осведомлённые',\n",
              "   'источники']],\n",
              " [['B-GPE',\n",
              "   'I-GPE',\n",
              "   'I-GPE',\n",
              "   'O',\n",
              "   'B-GPE',\n",
              "   'O',\n",
              "   'B-DATE',\n",
              "   'I-DATE',\n",
              "   'I-DATE',\n",
              "   'O',\n",
              "   'B-TIME',\n",
              "   'I-TIME',\n",
              "   'I-TIME',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'B-GPE',\n",
              "   'B-PERSON',\n",
              "   'I-PERSON',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'B-MONEY',\n",
              "   'I-MONEY',\n",
              "   'I-MONEY',\n",
              "   'O',\n",
              "   'B-DATE',\n",
              "   'I-DATE',\n",
              "   'I-DATE',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'B-ORG',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O']]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQ1phPKisJMz"
      },
      "source": [
        "records = corus.persons.load_persons(path)\n",
        "pavlova_person_set = set([])\n",
        "for rec in records:\n",
        "  try:\n",
        "    ner = ner_model([rec.text])\n",
        "    pv_txt, pv_lbls = ner_model([rec.text])[0], ner_model([rec.text])[1]\n",
        "    \n",
        "    for ind, lbl in enumerate(pv_lbls[0]):\n",
        "      if 'PERSON' in str(lbl):\n",
        "        person = pv_txt[0][ind]\n",
        "        pavlova_person_set.add(person)\n",
        "  except:\n",
        "    continue\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haQqr8PYL-u_"
      },
      "source": [
        "pavlova_person_set.intersection(set(['Хаммарберг']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hw7QPqtpLRW_",
        "outputId": "dd9f400a-d61a-4829-8ef8-81b5cbe228de"
      },
      "source": [
        "print(f'recall = {len(pavlova_person_set.intersection(person_set))/len(person_set)*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "recall = 61.96%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2aWYakhhxrK",
        "outputId": "cdb008d2-3bfe-435f-db43-7324691ec96e"
      },
      "source": [
        "print(f'FP = {len(pavlova_person_set - person_set)/len(person_set):.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FP = 0.03%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v40nGwysiHJq",
        "outputId": "24793977-3c03-47e1-b760-bbbd32a6674e"
      },
      "source": [
        "print(f'FN = {len(person_set - pavlova_person_set)/len(person_set):.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FN = 0.38%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Gb07h4yiUYl"
      },
      "source": [
        "Результат гораздо лучше, чем у nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3UbrTpeiigz"
      },
      "source": [
        "Третью часть сделать уже не успеваю ((("
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcnyy2y5ie86"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}